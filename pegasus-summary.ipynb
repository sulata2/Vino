{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HGnnfYQ8MuO",
        "outputId": "6b68beda-3da7-4b4a-ef67-cfb7ebd18cfb"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 12.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 52.9MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=d745c99acde95bbabd344e738b032b5b392f3b10b2fbc8e4123d5077c3a2e526\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQBNZM-Kdynm",
        "outputId": "1300a1c0-9256-4f93-d265-59caa3c83078",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install SentencePiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SentencePiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\r\u001b[K     |▎                               | 10kB 18.1MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 24.4MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 28.2MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 20.1MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 17.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 14.3MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 15.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 14.1MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 14.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 16.1MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 16.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 16.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 16.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 16.1MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 16.1MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 16.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 16.1MB/s \n",
            "\u001b[?25hInstalling collected packages: SentencePiece\n",
            "Successfully installed SentencePiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDg4ZsNJlY87",
        "outputId": "b16f2a27-5b1f-4ca9-e7fd-f38d9e6aa141",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "import torch\n",
        "src_text = open(\"/content/data/conversation4-POC-ftp.txt\", \"r\").readlines()\n",
        "#src_text = [\n",
        "#    \"\"\" PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\"\"\n",
        "#]\n",
        "\n",
        "model_name = 'google/pegasus-xsum'\n",
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
        "\n",
        "batch = tokenizer.prepare_seq2seq_batch(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(torch_device)\n",
        "translated = model.generate(**batch)\n",
        "\n",
        "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "\n",
        "print('tgt_text' , tgt_text)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:3221: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of 🤗 Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tgt_text ['Call centre agent: Hi, thanks for calling net service.', 'A selection of photos from around the world this week:', 'Customer: Hi, my Internet keeps disconnecting.', 'A selection of photos from around the world this week:', \"Agent: Hi, I'm sorry, but I'm not able to help you at the moment.\", 'How much do you know about your bank account?', 'A selection of photos from around the world this week:', \"A look back at some of the most memorable moments from this year's BBC Sports Personality of the Year awards.\", 'A selection of photos from around the world this week:', 'Sir, can you tell me the name of the customer?', 'A selection of photos from around the world this week:', \"Agent: What's the name of the city?\", 'A selection of photos from around the world this week:', 'Daniel:', 'What is the best way to get a refund on your car insurance?', 'A selection of photos from around the world this week:', \"Customer: I'm having problems with my internet.\", 'A selection of photos from around the world this week:', 'Agent : Is your house without power?', 'A selection of photos from around the world this week:', 'Customer: are you serious?', 'A selection of photos from around the world this week:', 'Can you tell me what is going on?', 'A selection of photos from around the world this week:', \"Customer: I've been very camp.\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REyh-iwPlf02",
        "outputId": "7fdc1839-214e-4024-b83f-38e0b05ff8a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tgt_text[3]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A selection of photos from around the world this week:'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXcdxVoMmxiJ"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "import torch\n",
        "src_text = open(\"/content/data/conversation4-POC-ftp.txt\", \"r\").readlines()\n",
        "#src_text = [\n",
        "#    \"\"\" PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\"\"\n",
        "#]\n",
        "\n",
        "model_name = 'google/pegasus-cnn_dailymail'\n",
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
        "\n",
        "batch = tokenizer.prepare_seq2seq_batch(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(torch_device)\n",
        "translated = model.generate(**batch)\n",
        "\n",
        "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "\n",
        "print('tgt_text' , tgt_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RW6yoQ28QJE",
        "outputId": "a271dda5-6c24-4399-bce0-6317bc664f4b"
      },
      "source": [
        "!python \"/content/data/pegasus-summary.py\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-22 10:51:54.318624: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:3221: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of 🤗 Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
            "  FutureWarning,\n",
            "tgt_text ['Call centre agent: Hi, thanks for calling net service.', 'A selection of photos from around the world this week:', 'Customer: Hi, my Internet keeps disconnecting.', 'A selection of photos from around the world this week:', \"Agent: Hi, I'm sorry, but I'm not able to help you at the moment.\", 'How much do you know about your bank account?', 'A selection of photos from around the world this week:', \"A look back at some of the most memorable moments from this year's BBC Sports Personality of the Year awards.\", 'A selection of photos from around the world this week:', 'Sir, can you tell me the name of the customer?', 'A selection of photos from around the world this week:', \"Agent: What's the name of the city?\", 'A selection of photos from around the world this week:', 'Daniel:', 'What is the best way to get a refund on your car insurance?', 'A selection of photos from around the world this week:', \"Customer: I'm having problems with my internet.\", 'A selection of photos from around the world this week:', 'Agent : Is your house without power?', 'A selection of photos from around the world this week:', 'Customer: are you serious?', 'A selection of photos from around the world this week:', 'Can you tell me what is going on?', 'A selection of photos from around the world this week:', \"Customer: I've been very camp.\"]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/data/pegasus-summary.py\", line 26, in <module>\n",
            "    f.write(tgt_text)\n",
            "TypeError: write() argument must be str, not list\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI7Gh5H3lN4I",
        "outputId": "b82cf20f-3a3d-4b1d-88d1-4ef4c88d8aa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "tgt_text[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-54aae11c81ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtgt_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tgt_text' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLWpg1dt3BzM",
        "outputId": "567645bd-b783-4f08-b82e-69931fcac205",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "print('tgt_text' , tgt_text)\n",
        "with open('/content/data/summary_poc.txt', 'w') as f:\n",
        "#    f.write('Doe, a deer, a female deer\\n')\n",
        "    f.write(tgt_text)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f3ab98a108b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tgt_text'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtgt_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/data/summary_poc.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#    f.write('Doe, a deer, a female deer\\n')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tgt_text' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7b29ya3jZlC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}